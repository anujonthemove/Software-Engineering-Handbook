{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Software Engineering Handbook","text":"<p>\ud83d\udea7 Under construction\ud83d\udea7</p> <ul> <li>Sharing tried and tested things one by one here to the larger audience.</li> </ul>"},{"location":"ide/vs-code/","title":"Vs code","text":""},{"location":"ide/vs-code/#optional-vs-code-settings","title":"Optional VS Code Settings","text":"<p>VS Code settings that will enable you to automatically clean up your code as and when you save the file</p> <pre><code>{\n\"python.linting.enabled\": true,\n\"python.linting.flake8Enabled\": true,\n\"python.analysis.typeCheckingMode\": \"basic\",\n\"python.formatting.provider\": \"black\",\n\"editor.formatOnSaveMode\": \"file\",\n\"editor.formatOnSave\": true,\n\"editor.codeActionsOnSave\": {\n\"source.organizeImports\": true\n},\n}\n</code></pre>"},{"location":"ide/vs-code/#must-install-vs-code-extensions-for-developers","title":"Must install VS Code extensions for developers","text":"<ol> <li>Python: https://marketplace.visualstudio.com/items?itemName=ms-python.python</li> <li>Flake8: https://marketplace.visualstudio.com/items?itemName=ms-python.flake8</li> <li>iSort: https://marketplace.visualstudio.com/items?itemName=ms-python.isort</li> <li>Jupyter: https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter</li> <li>Pylance: https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance</li> <li>autoDocstring: https://marketplace.visualstudio.com/items?itemName=njpwerner.autodocstring</li> <li></li> </ol> <p>https://marketplace.visualstudio.com/items?itemName=GitHub.github-vscode-theme https://marketplace.visualstudio.com/items?itemName=oderwat.indent-rainbow https://marketplace.visualstudio.com/items?itemName=bierner.markdown-preview-github-styles https://marketplace.visualstudio.com/items?itemName=bierner.markdown-mermaid https://marketplace.visualstudio.com/items?itemName=vscode-icons-team.vscode-icons</p> <p>https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack</p>"},{"location":"python-machine-learning-template/","title":"\ud83e\udde0 Philosophy","text":"<p>This template is meticulously designed to encapsulate the three core components of a Machine Learning project: Code, Data, and Models. The primary objective is to cohesively organize these components within the project structure, thereby enhancing manageability and maintainability.</p> <ul> <li> <p>\ud83d\udd22 Code: The codebase is the backbone of your project. It is typically managed through version control and is pushed to a remote repository on platforms such as GitHub, GitLab, BitBucket, or any other cloud-based Git service. This ensures that your work is safely stored and can be shared with others.</p> </li> <li> <p>\ud83d\udcca Data &amp; Models: These are the lifeblood of your machine learning project. They should be incorporated within the project structure. However, due to their potentially large file size, they should never be pushed to the git repository. Instead, consider using data version control tools or cloud storage solutions to manage your data and models.</p> </li> </ul> <pre><code>\ngraph LR\n  P[\"Machine Learning Project\"]\n    P --&gt; C[\"Code\"]\n    P --&gt; D[\"Data\"]\n    P --&gt; M[\"Models\"]\n    C --&gt; G[\"GitHub/GitLab/BitBucket/Cloud-based Git\"]\n    D --&gt; S[\"Storage (Not in Git)\"]\n    M --&gt; S</code></pre> Intended organization"},{"location":"python-machine-learning-template/#common-challenges","title":"\u26a0\ufe0f ** Common Challenges**","text":"<p>Developers often encounter the following problems during the development process:</p> <ul> <li> <p>\ud83d\ude46 Data and Model Segregation: They frequently need to separate data, models, and other artifacts from their code before pushing changes to a remote repository. This process can be time-consuming and error-prone.</p> </li> <li> <p>\ud83e\udd26 Accidental Uploads: There's always a risk of inadvertently pushing unwanted files to the remote repository, which can clutter the repository or even expose sensitive data.</p> </li> </ul>"},{"location":"python-machine-learning-template/#our-solution","title":"\ud83c\udfaf Our Solution","text":"<p>This template is designed to mitigate these challenges with the following features:</p> <ul> <li> <p>\ud83d\uddc2\ufe0f Pre-defined Project Structure: The template offers a well-organized layout to store all your files, data, models, and other artifacts. This structure remains consistent throughout the project's life cycle, promoting a clean and organized development environment.</p> </li> <li> <p>\ud83d\udee1\ufe0f .gitignore: A carefully crafted .gitignore file is included to ensure that unwanted files are not pushed to the remote repository. This helps to prevent accidental uploads and keeps your repository clean and focused.</p> </li> </ul>"},{"location":"python-machine-learning-template/#project-directory-structure","title":"\ud83d\uddc2\ufe0f Project Directory Structure","text":"<pre><code>.\n\u251c\u2500\u2500 config/                  &lt;- \ud83d\udcc2 Configuration files [.ini, .json, .yaml]\n\u251c\u2500\u2500 data/                    &lt;- \ud83d\udcc2 Images, numpy data objects, text files\n\u251c\u2500\u2500 docs/                    &lt;- \ud83d\udcc2 Store .md files. Used by Mkdocs for Project Documentation\n\u251c\u2500\u2500 helpers/                 &lt;- \ud83d\udcc2 Utility/helper files/modules for the project\n\u251c\u2500\u2500 html/                    &lt;- \ud83d\udcc2 Store .html files and accompanying assets. Used by pdoc3 for API Documentation\n\u251c\u2500\u2500 logs/                    &lt;- \ud83d\udcc2 Log files generated by the project during execution\n\u251c\u2500\u2500 models/                  &lt;- \ud83d\udcc2 Model files [.h5, .pkl, .pt] - pre-trained weight files, snapshots, checkpoints\n\u251c\u2500\u2500 notebooks/               &lt;- \ud83d\udcc2 Jupyter Notebooks\n\u251c\u2500\u2500 references/              &lt;- \ud83d\udcc2 Data dictionaries, manuals, and all other explanatory materials\n\u251c\u2500\u2500 scripts/                 &lt;- \ud83d\udcc2 Utility scripts for various project-related tasks\n\u251c\u2500\u2500 src/                     &lt;- \ud83d\udcc2 Source code (.py files)\n\u251c\u2500\u2500 tests/                   &lt;- \ud83d\udcc2 Unit tests for the project\n\u251c\u2500\u2500 workspaces/              &lt;- \ud83d\udcc2 Multi-user workspace that can be used in the case of a single machine\n\u251c\u2500\u2500 .env-template            &lt;- \ud83d\udd27 Template for the .env file\n\u251c\u2500\u2500 .gitattributes           &lt;- \ud83d\udd27 Standard .gitattributes file\n\u251c\u2500\u2500 .gitignore               &lt;- \ud83d\udcdb Standard .gitignore file\n\u251c\u2500\u2500 .pre-commit-config.yaml  &lt;- \ud83d\udd27 Config file for Git Hooks\n\u251c\u2500\u2500 LICENSE                  &lt;- \ud83e\udea7 License file [choose your appropriate license from GitHub]\n\u251c\u2500\u2500 mkdocs.yml               &lt;- \ud83d\uddde\ufe0f Base config file required for Mkdocs\n\u251c\u2500\u2500 Pipfile                  &lt;- \ud83d\uddc3\ufe0f Most commonly used python packages\n\u251c\u2500\u2500 project_setup.bat        &lt;- \ud83d\udcdc Project script for Windows OS\n\u251c\u2500\u2500 project_setup.sh         &lt;- \ud83d\udcdc Project script for Linux/MacOS\n\u251c\u2500\u2500 README.md                &lt;- \ud83d\udcdd Project readme\n\u251c\u2500\u2500 setup.py                 &lt;- \ud83d\udce6\ufe0f For installing &amp; packaging the project\n\u2514\u2500\u2500 tox.ini                  &lt;- \ud83d\udd27 General-purpose package configuration manager\n</code></pre> <p>\ud83d\ude80 By adopting this clean and organized project structure, you can enhance accessibility and maintainability, allowing for seamless development and collaboration.</p> <p>\ud83d\udc69\u200d\ud83d\udcbb Give it a try and experience the benefits of a simplified and well-structured project! Happy coding! </p>"},{"location":"python-machine-learning-template/#show-your-support","title":"\ud83c\udf1f Show Your Support","text":"<p>If our work has benefitted you, we kindly ask you to give it a star on GitHub \ud83e\udd29. Your support serves as a great motivation for us to continue enhancing the project and introducing new features. \ud83d\udcaa</p> <p>We deeply appreciate your support! \u2764\ufe0f</p>"},{"location":"python-machine-learning-template/dot-env/","title":"\u26d4 Credential Management using .env","text":"<p>The <code>.env</code> file is a simple and effective way to manage credentials and other environment-specific settings. Here's how you can use it:</p>"},{"location":"python-machine-learning-template/dot-env/#store-proxy-details","title":"\ud83c\udf10 Store proxy details","text":"<p>If you're working behind a proxy, you can store your proxy information in the <code>.env</code> file. These will be automatically loaded and utilized by <code>Pipenv</code> during package installation. Here's the format:</p> <pre><code>HTTP_PROXY='http://user:password@your-proxy-url:port'\nHTTPS_PROXY='https://user:password@your-proxy-url:port'\n</code></pre> <p>Replace <code>user</code>, <code>password</code>, <code>your-proxy-url</code>, and <code>port</code> with your actual proxy details.</p>"},{"location":"python-machine-learning-template/dot-env/#store-credentialssecretskeys","title":"\ud83d\udddd\ufe0f Store credentials/secrets/keys","text":"<p>You can also store API keys and other credentials in the <code>.env</code> file. Here's an example of how to store an API key:</p> <pre><code>OPENAI_API_KEY='xxxx-xxxx'\n</code></pre> <p>Replace <code>xxxx-xxxx</code> with your actual OpenAI API key.</p>"},{"location":"python-machine-learning-template/dot-env/#using-env-variables-inside-python-code","title":"\ud83d\udc68\u200d\ud83d\udd27 Using .env variables inside Python code","text":"<p>To utilize the variables defined in the <code>.env</code> file into your Python code, we recommend using the <code>python-decouple</code> library. This library simplifies the process of separating settings from your source code, making it easier to change these settings without modifying the code itself.</p> <p>Here's an example of how you can use <code>python-decouple</code> to access the credentials stored in your <code>.env</code> file:</p> <pre><code>from decouple import config\n\n# Get the OpenAI API key\nopenai_api_key = config('OPENAI_API_KEY')\n\n# Get the HTTP proxy\nhttp_proxy = config('HTTP_PROXY')\n\n# Get the HTTPS proxy\nhttps_proxy = config('HTTPS_PROXY')\n</code></pre> <p>In this code, <code>config('OPENAI_API_KEY')</code>, <code>config('HTTP_PROXY')</code>, and <code>config('HTTPS_PROXY')</code> retrieve the values of <code>OPENAI_API_KEY</code>, <code>HTTP_PROXY</code>, and <code>HTTPS_PROXY</code> from the <code>.env</code> file, respectively.</p> <p>Note</p> <p>The <code>.env</code> file does not get committed to your version control system. It typically contains sensitive information that should not be shared publicly. </p>"},{"location":"python-machine-learning-template/faqs/","title":"\ud83d\udcfb Frequently Asked Questions","text":"1. Is this project structure/repository inspired by the cookie-cutter project template? <ul> <li> <p>No, this project structure is not directly inspired by the cookie-cutter project template. While there might be some similarities in naming conventions, this Python Machine Learning Template was specifically designed to cater to the unique needs of various machine learning projects, including reinforcement learning, computer vision, and natural language processing. That being said, we do appreciate and recommend the Jupyter Notebook naming convention used in the cookie-cutter project template.</p> </li> <li> <p>To use this template, you don't need to install any additional packages or tools such as cookiecutter. You can directly use it on GitHub by clicking the \"Use this template\" button. Once you create the project, the cleanup process is automatically handled by a GitHub actions bot.</p> </li> <li> <p>We hold the cookiecutter project in high regard; it's beautifully packaged and serves as an excellent starting point for new projects. However, our template differs from cookiecutter in several ways:</p> <ol> <li> <p>It doesn't require any additional package installations. Technically, only Python is required, and the virtual environment (venv) comes bundled with new Python releases above 3.3.</p> </li> <li> <p>We didn't want our users to install any additional packages or go through extensive configurations just to start the project. Hence, we created this template, which requires minimal setup steps. </p> </li> </ol> </li> </ul> 2. What are the main advantages of using this template? <ul> <li>The folder structure has been meticulously designed to ensure organization and efficiency.</li> <li>All components within the template have been seamlessly integrated to work together effectively.</li> <li>The only prerequisite for using this template is having Python and a virtual environment (venv) installed. No additional Python packages are required. This is particularly advantageous in organizations with restricted package access, as this template only relies on Python and venv.</li> <li>We have provided comprehensive documentation for this template, addressing all aspects and potential challenges. This includes practical issues encountered during our day-to-day work, ensuring you have a well-rounded understanding of the template's functionality and usage.</li> </ul> 3. How is it different from other available templates? <ul> <li>Our setup scripts are designed for both Linux/MacOS and Windows operating systems, ensuring a smooth setup process regardless of your platform.</li> <li>Our directory structure is comprehensive, designed to accommodate all types of machine learning projects, providing a solid foundation for your work.</li> <li>The template stands out with its minimal dependencies, eliminating the need for specific Python packages or complex utilities.</li> <li>While there are many excellent templates available, most of them require make or cmake utilities which can be challenging to work with on Windows. To address this issue, we have developed dedicated project setup scripts for both Windows and Linux, eliminating the need for users to worry about platform compatibility.</li> </ul>"},{"location":"python-machine-learning-template/gitattributes/","title":"\ud83d\udd79\ufe0f Managing File Attributes in Git Repository","text":""},{"location":"python-machine-learning-template/gitattributes/#problem","title":"\ud83d\ude46 Problem","text":"<p>During the development of a large-scale project involving multiple developers across various platforms, we encountered a recurring issue. Developers were reporting an error when attempting to commit their code.</p> <p>Error</p> <pre><code>git commit get fatal error \"fatal: CRLF would be replaced by LF in...\"\n</code></pre>"},{"location":"python-machine-learning-template/gitattributes/#solution","title":"\ud83d\udc81 Solution","text":"<p>The immediate solution was to instruct each developer to add the following configuration to their git config: </p> <pre><code>'git config --global core.autocrlf false'. \n</code></pre> <p>However, we sought a more proactive approach to prevent such an error from arising in the first place.</p> <p>Our research led us to the use of <code>.gitattributes</code>, which we decided to incorporate into our template.</p> <p>The <code>.gitattributes</code> file is a configuration file that allows you to specify attributes and behaviors for certain files in your repository. Define the line-ending style, binary or text attributes, and more.</p> <p>Part of the configuration we implemented is as follows:</p> <pre><code># Normalize line endings to LF on check-in and prevent conversion to CRLF when checked out.\n# This is necessary to prevent newline related issues, \n#  such as those that might occur after running the build script.\n\n.*      text eol=lf\n*.css   text eol=lf\n*.html  text eol=lf\n*.js    text eol=lf\n*.json  text eol=lf\n*.scss  text eol=lf\n*.md    text eol=lf\n*.rs    text eol=lf\n*.sh    text eol=lf\n*.toml  text eol=lf\n*.txt   text eol=lf\n*.xml   text eol=lf\n*.yaml  text eol=lf\n*.yml   text eol=lf\n*.py    text eol=lf\n</code></pre> <p>This configuration ensures that for the specified file types:</p> <ul> <li>\ud83d\udd04 Line endings are normalized to LF upon check-in.</li> <li>\ud83d\udeab Conversion to CRLF is prevented when they are checked out.</li> </ul> <p>This helps to prevent newline related issues, such as those that might occur after running the build script.</p> <p>Reference:</p> <ul> <li>git commit get fatal error \"fatal: CRLF would be replaced by LF in\"</li> </ul>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/","title":"\ud83d\udcec Loading Configuration and Data Files in Python Projects","text":"<p>This section provides instructions on how to load configuration files (such as <code>config.yml</code>) and data files (such as <code>amazon_alexa.tsv</code>) in Python projects. The instructions are applicable when the configuration files are located in a <code>config</code> directory and the data files are located in a <code>data</code> directory at the root level of the project. You may want to check the setup.py section to understand the importance of this section.</p> <p>Your files could be structured as below:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 text\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 amazon_alexa.tsv\n\u251c\u2500\u2500 helpers\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 helper.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 notebooks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 test_code.ipynb\n\u251c\u2500\u2500 setup.py\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 test_code.py\n</code></pre>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-configuration-files","title":"\ud83e\ude9d Loading Configuration Files","text":""},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-using-importlibresources","title":"\u2694\ufe0f Loading using <code>importlib.resources</code>","text":"<p>Configuration files (like <code>config.yml</code>) can be loaded as a package resource using the <code>importlib.resources</code> module in Python. </p> <p>Here's a sample code snippet:</p> test_code.ipynb<pre><code>import yaml\nimport importlib.resources\n\ndef read_config():\n    # Read the resource as text\n    resource_string = importlib.resources.read_text('config', 'config.yml')\n\n    # Load the yaml file\n    config = yaml.safe_load(resource_string)\n\n    return config\n</code></pre> <p>In this code, <code>'config'</code> is the name of the package where the <code>config.yml</code> file is located, and <code>'config.yml'</code> is the name of the resource. It should be a file in the <code>config</code> package.</p> <p>To load the configuration file as a package resource, you need to include it in your <code>setup.py</code> file. Here's how you can do it:</p> setup.py<pre><code>from setuptools import find_packages, setup\n\nsetup(\n    name=\"Test-Project\", \n    version=\"1.0\", \n    packages=find_packages(),\n\n    # added these lines\n    package_data={'': ['config/*.yml']},\n    include_package_data=True,\n)\n</code></pre> <p>In this code, <code>package_data={'': ['config/*.yml']}</code> tells setuptools to include all <code>.yml</code>files in the <code>config</code> directory in any package, and <code>include_package_data=True</code> tells <code>setuptools</code> to include any data files specified in <code>package_data</code>.</p> <p>Caution</p> <p>This way you are telling python that your <code>config.yml</code> should be treated as a part of the project package. When you run the code for the first time, in order to optimize loading for the second time, python will cache this file. Now, if you change some values in the <code>config.yml</code> file, and re-run the code, you might get the previous values that were set in the config.yml file. This is not what you intended to do but python does it inherently to save loading the next time. It is strictly adviced not to use this method for loading config files, you may use it for those files which are not expected to change much. Even re-running <code>pipenv install -e .</code> command did not overwrite the cached config.yml file. You should choose this method for files that suites your purpose.</p>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-as-a-regular-file","title":"\ud83e\uddf2 Loading as a Regular File","text":"<p>Alternatively, you can load the configuration file as a regular file without including it as a package resource. </p> <p>Here's how you can do it:</p> test_code.ipynb<pre><code>import yaml\nimport os\n\ndef read_config():\n    # Get the current working directory\n    current_dir = os.getcwd()\n\n    # Get the config file path\n    config_file_path = os.path.join(current_dir, '..', 'config', 'config.yml')\n\n    # Resolve the relative path to an absolute path\n    config_file_path = os.path.abspath(config_file_path)\n\n    # Load the yaml file\n    with open(config_file_path, 'r') as file:\n        config = yaml.safe_load(file)\n\n    return config\n</code></pre> <p>In this code, <code>os.getcwd()</code> gets the current working directory, <code>os.path.join(current_dir, '..', 'config', 'config.yml')</code> constructs the path to the config file relative to the current working directory, <code>os.path.abspath(config_file_path)</code> resolves the relative path to an absolute path, and <code>yaml.safe_load(file)</code> loads the yaml file.</p>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-with-pkg_resources-this-will-soon-get-deprecated","title":"\ud83d\udca3 Loading with pkg_resources (this will soon get deprecated)","text":"<p>You can also load the configuration file using <code>pkg_resources</code>, but please note that <code>pkg_resources</code> is being phased out in favor of <code>importlib.resources</code>. Here's how you can do it:</p> test_code.ipynb<pre><code>import pkg_resources\nimport yaml\n\ndef read_config():\n    config_path = pkg_resources.resource_filename('config', 'config.yml')\n    with open(config_path, 'r') as file:\n        config = yaml.safe_load(file)\n    return config\n</code></pre>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-data-files","title":"\ud83d\udcc8 Loading Data Files","text":"<p>Data files (like <code>amazon_alexa.tsv</code>) can be loaded using the pandas library in Python. Here's a sample code snippet:</p> test_code.ipynb<pre><code>import pandas as pd\nimport os\n\ndef read_data():\n    # Get the current working directory    \n    current_dir = os.getcwd()\n\n    # Get the data file path\n    data_file_path = os.path.join(current_dir, '..', 'data', 'text', 'amazon_alexa.tsv')\n\n    # Resolve the relative path to an absolute path\n    data_file_path = os.path.abspath(data_file_path)\n\n    # Read the data file\n    data = pd.read_csv(data_file_path, sep='\\t')\n\n    return data\n</code></pre> <p>In this code, <code>os.getcwd()</code> gets the current working directory, <code>os.path.join(current_dir, '..', 'data', 'text', 'amazon_alexa.tsv')</code> constructs the path to the data file relative to the current working directory, o<code>s.path.abspath(data_file_path)</code> resolves the relative path to an absolute path, and <code>pd.read_csv(data_file_path, sep='\\t')</code> reads the data file into a pandas DataFrame.</p> <p>Please replace <code>'..'</code>, <code>'data'</code>, <code>'text'</code>, and <code>'amazon_alexa.tsv'</code> with the actual relative path from your script or notebook to amazon_alexa.tsv if it's different in your project.</p>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/#running-python-scripts-from-the-root-of-the-project","title":"\ud83e\uddea Running Python Scripts from the Root of the Project","text":""},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-config-file","title":"\ud83e\udded Loading config file","text":"<p>When you run a Python script from the root of the project (for example, <code>python src/test_code.py</code>), the current working directory is the root of the project, not the directory where the script is located. In this case, you can use the <code>__file__</code> variable to get the directory of the script, and then construct the path to the configuration or data file relative to the script directory. Here's how you can do it:</p> test_code.py<pre><code>import yaml\nimport os\n\ndef read_config():\n    # Get the directory of the script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Get the config file path\n    config_file_path = os.path.join(script_dir, '..', 'config', 'config.yml')\n\n    # Load the yaml file\n    with open(config_file_path, 'r') as file:\n        config = yaml.safe_load(file)\n\n    return config\n</code></pre> <p>In this code, <code>os.path.dirname(os.path.abspath(__file__))</code> gets the directory of the script, <code>os.path.join(script_dir, '..', 'config', 'config.yml')</code> constructs the path to the config file relative to the script directory, and <code>yaml.safe_load(file)</code> loads the yaml file.</p>"},{"location":"python-machine-learning-template/loading-files-in-python-projects/#loading-data-files_1","title":"\ud83c\udfd7\ufe0f Loading data files","text":"test_code.py<pre><code>import pandas as pd\nimport os\n\ndef read_data():\n    # Get the directory of the script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Get the data file path\n    data_file_path = os.path.join(script_dir, '..', 'data', 'text', 'amazon_alexa.tsv')\n\n    # Read the data file\n    data = pd.read_csv(data_file_path, sep='\\t')\n\n    return data\n</code></pre> <p>In this code, <code>os.path.dirname(os.path.abspath(__file__))</code> gets the directory of the script, <code>os.path.join(script_dir, '..', 'data', 'text', 'amazon_alexa.tsv')</code> constructs the path to the data file relative to the script directory, and <code>pd.read_csv(data_file_path, sep='\\t')</code> reads the data file into a pandas DataFrame.</p>"},{"location":"python-machine-learning-template/miscellaneous/","title":"Miscellaneous","text":""},{"location":"python-machine-learning-template/miscellaneous/#creating-detailed-project-documentation-with-mkdocs-and-material-for-mkdocs","title":"\ud83d\udcda Creating Detailed Project Documentation with MkDocs and Material for MkDocs","text":"<p>MkDocs is a handy tool that lets you create project documentation using Markdown. It's easy to use and quickly generates a static site for your documentation. The result is a professional, searchable, and customizable site, making it a great choice for projects of all sizes.</p> <p>To make your MkDocs experience even better, you can use Material for MkDocs. This add-on provides a clean, responsive theme for your MkDocs-generated site. It supports over 60 languages and works perfectly on all devices. With Material for MkDocs, your project documentation can look more professional and be easier to use.</p> <p>To start using these tools, you can check out their official documentation. Remember, code that is well-documented is easier to maintain, understand, and use, so these tools are really important for your project.</p> <p>Together, these tools can help you create detailed project documentation, just like this Software Engineering guide you're reading now. \ud83e\udd29</p> <p>MkDocs needs you to keep the following structure:</p> <pre><code>\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 index.md\n\u2514\u2500\u2500 mkdocs.yml\n</code></pre> <p>In this structure, all the markdown files are kept in the docs folder, and all the configuration is done in the mkdocs.yml file. The MkDocs python package is installed as part of the development packages, and to make it easy to use, we've already included the above structure in this template.</p> <p>The installation of the Mkdocs-material theme package is up to you. It can be installed with the following command:</p> <pre><code>pipenv install mkdocs-material\n</code></pre>"},{"location":"python-machine-learning-template/miscellaneous/#auto-generating-api-documentation-with-pdoc3","title":"\ud83d\udcdc Auto-Generating API Documentation with Pdoc3","text":"<p>Pdoc3 is a handy Python library that simplifies the process of generating API documentation for your Python projects. It operates by extracting docstrings from your public modules and objects, a functionality similar to tools like sphinx-apidoc or sphinx.ext.autodoc. However, Pdoc3 stands out due to its less complex and more lightweight design, making it an ideal choice for small to medium-sized projects.</p> <p>One of the key features of Pdoc3 is its support for Markdown. This is a big plus for many developers who find Markdown more intuitive and user-friendly than reStructuredText (reST). By using Pdoc3, you can ensure that your code is well-documented and easy to understand, which encourages others to use and contribute to your project.</p> <p>Pdoc3 generates attractive HTML documentation for all your codes. By default, these documents are stored in a folder named <code>html</code>, which is already included as part of this template. The Pdoc3 Python package is also installed along with other development packages when you set up your project using our setup scripts. We've got you covered \ud83d\ude0e</p>"},{"location":"python-machine-learning-template/miscellaneous/#preserving-directory-structure-with-gitkeep","title":"\ud83d\udcc1 Preserving Directory Structure with <code>.gitkeep</code>","text":"<p>Git doesn't track empty directories. This can pose a challenge when you want to keep a specific directory structure in your project, even if some directories don't contain any files. The <code>.gitkeep</code> file is a workaround for this.</p> <p>The <code>.gitkeep</code> file isn't an official Git feature. It's a convention that the community has adopted. Git will track directories that contain at least one file. By adding a <code>.gitkeep</code> file to an otherwise empty directory, you can ensure that Git tracks it.</p> <p>In this project template, we've used <code>.gitkeep</code> files to push empty folders to the Git repository. This preserves the directory structure of the template when you clone or download it.</p> <p>The name \"<code>.gitkeep</code>\" isn't special. You could use any filename to get Git to track an empty directory. The community uses \"<code>.gitkeep</code>\" because it's self-explanatory \u2013 anyone looking at the repository will understand its purpose. \ud83e\udd13</p>"},{"location":"python-machine-learning-template/miscellaneous/#adopting-the-cookiecutter-naming-convention-for-jupyter-notebooks","title":"\ud83c\udfab Adopting the Cookiecutter Naming Convention for Jupyter Notebooks","text":"<p>Machine Learning projects typically commence with exploratory data analysis. Jupyter Notebook is an invaluable tool for this phase, thanks to its seamless integration with libraries such as matplotlib, seaborn, plotly, bokeh, and pandas. These libraries enhance the visual output on Notebooks, making them an essential part of the entire Machine Learning project life cycle.</p> <p>However, without a consistent naming convention, managing these notebooks can become a daunting task. It's not uncommon to find notebooks left unnamed, resulting in files like <code>Untitled.ipynb</code> or <code>Untitled1.ipynb</code>. Given the typically lengthy nature of Machine Learning code, it can be challenging to identify the final version of the code.</p> <p>While designing this template, we discovered a naming convention in Cookiecutter templates and were instantly impressed. We have personally implemented this convention in numerous projects to maintain organization. We strongly encourage users of this template to adopt this convention if they don't already have one in place. It has proven to be highly effective. </p> <p>Here is the convention, directly taken from Cookiecutter:</p> <p>Naming convention is a number (for ordering), the creator's initials, and a short <code>-</code> delimited description, e.g. <code>1.0-jqp-initial-data-exploration</code>. i.e., it follows a format of <code>&lt;number&gt;-&lt;initials&gt;-&lt;short-description&gt;</code>, e.g., <code>1.0-jqp-initial-data-exploration.ipynb</code></p>"},{"location":"python-machine-learning-template/pipenv/","title":"\ud83d\udce2 Pipenv for Dependency Management","text":"<p>If you have been using pip for your Python package installations \ud83d\udce6 and requirements.txt \ud83d\udcdc for package dependency creation, you might have encountered the following issues:</p> <ol> <li> <p>\ud83e\udde9 Dependency Mismatch: When sharing or deploying your project in different environments (like QA or Production), you typically share the <code>requirements.txt</code> file. However, if your project has been in development for a long time, there's a good chance that package installation may fail \u274c on the new machine due to dependency mismatches. This can lead to a lot of time being wasted troubleshooting \ud83d\udd27\ud83d\udd0d and resolving these issues.</p> </li> <li> <p>\ud83c\udf10 Long Proxy URL: When working behind a proxy, you may have to manually enter a long URL every time you want to install a Python package. This can be quite frustrating \ud83d\ude24 and time-consuming \u23f0.</p> </li> </ol> <p>To address these challenges, we recommend using Pipenv \ud83c\udf81. Pipenv introduces a more efficient approach to package management by maintaining two files:</p> <ul> <li> <p>\ud83d\udcc4 Pipfile: This human-readable file serves as a comprehensive dependency manifest for both base and development packages. It provides a clear and manageable overview of your project's dependencies.</p> </li> <li> <p>\ud83d\udd12 Pipfile.lock: This file stores the cryptographic hashes of all packages, ensuring consistent installations across different environments. Pipenv automatically resolves dependencies based on the information in the lock file, eliminating the chances of dependency conflicts.</p> </li> </ul> Advantages of using Pipenv <ul> <li>\u2705 Simplified virtual environment management and package dependencies.</li> <li>\u2705 Automatic dependency resolution for installed packages.</li> <li>\u2705 Dependency locking to ensure reproducibility.</li> <li>\u2705 Seamless integration with existing Python tools like pip and PyPI.</li> <li>\u2705 Built-in environment activation when entering project directories.</li> <li>\u2705 Clear and readable output for easy troubleshooting.</li> <li>\u2705 Seamless integration with .env for loading environment variables during package installation.</li> <li>\u2705 Simplified handling of proxy URLs through automatic incorporation of environment variables by Pipenv.</li> </ul> <p>Check out Pipenv official documentation for more details!</p>"},{"location":"python-machine-learning-template/pipenv/#installing-from-custom-index-or-self-hosted-repository","title":"\ud83d\udce6 Installing from Custom Index or Self-Hosted Repository","text":"<p>If you're using a custom index or a self-hosted repository for your Python packages, you can specify these sources in your Pipfile. Here's how you can do it:</p> <pre><code>[[source]]\nurl = \"https://your-repo-name.com/\"\nverify_ssl = true\nname = \"jfrog\"\n\n[[source]]\nurl = \"https://your-repo-name.com/\"\nverify_ssl = false\nname = \"cdswrepo\"\n</code></pre> <p>In the above configuration:</p> <ul> <li> <p><code>url</code> is the URL of your custom index or self-hosted repository.</p> </li> <li> <p><code>verify_ssl</code> is a boolean value that determines whether SSL verification is required for the repository. Set it to true if SSL verification is needed; otherwise, set it to false.</p> </li> <li> <p><code>name</code> is a unique identifier for the source. You can choose any name that makes sense to you.</p> </li> </ul> <p>Replace <code>your-repo-name.com</code> with your actual repository URLs. Please ensure that you have the correct SSL verification setting for each repository. Incorrect configuration may lead to installation failures.</p>"},{"location":"python-machine-learning-template/pre-commit/","title":"\u2705 Ensuring Code Quality Before Commit","text":""},{"location":"python-machine-learning-template/pre-commit/#understanding-pre-commit-hooks-and-the-pre-commit-framework","title":"\ud83d\udcda Understanding Pre-commit Hooks and the Pre-commit Framework","text":"<p>Pre-commit hooks are scripts that run automatically before each commit to check your code and ensure it's ready to be committed. They're a type of \"hook\" \u2014 a script that Git executes before or after events such as: <code>commit</code>, <code>push</code>, <code>checkout</code>, and others. Pre-commit hooks are a great way to automate and standardize checks and tests, helping to catch issues before they cause problems.</p> <p>The Pre-commit Framework is a tool that manages and maintains multi-language pre-commit hooks. It helps you manage hooks installed in your repository and makes it easier to handle and reuse configurations across projects. </p>"},{"location":"python-machine-learning-template/pre-commit/#heres-how-it-works","title":"\ud83d\udc53 Here's how it works:","text":"<ol> <li>You specify a list of hooks you want in the <code>.pre-commit-config.yaml</code> file in your repository.</li> <li> <p>When you initialize pre-commit (using <code>pre-commit install</code>), it installs a hook script in your <code>.git/hooks</code> directory. This script will run every time you commit changes.</p> <p>Note</p> <p>If your <code>.venv</code> (virtual environment) is not currently active, proceed to the terminal and navigate to your project directory, activate your <code>.venv</code> according to your operating system, and then run the command <code>pre-commit install</code> to update the git hooks for your project.</p> </li> </ol> <p>When the hook script runs, it uses the configuration in your <code>.pre-commit-config.yaml</code> file to determine which hooks to run. These hooks can do things like checking syntax errors, fixing formatting issues, and even preventing commits that contain secrets.</p> <p>By using pre-commit hooks and the Pre-commit Framework, you can ensure that all commits meet your project's standards and that your codebase remains clean and well-organized.</p>"},{"location":"python-machine-learning-template/pre-commit/#pre-configured-pre-commit-hooks-in-this-template","title":"\ud83d\udd76 Pre-configured Pre-commit Hooks in this Template","text":"<p>This template comes pre-configured with several useful pre-commit hooks:</p>"},{"location":"python-machine-learning-template/pre-commit/#preventing-large-files-from-being-committed","title":"\ud83c\udf0a Preventing Large Files from Being Committed","text":"<p>This hook prevents large files (typically more than 5 MB) from being committed to Git. This is particularly useful in preventing accidental commits of large data files or model files.</p> <pre><code>- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v4.0.1\nhooks:\n- id: check-added-large-files\nname: Check for large files\ndescription: Prevents large files from being committed\nentry: check-added-large-files\nargs: [--maxkb=5120]\n</code></pre>"},{"location":"python-machine-learning-template/pre-commit/#auto-clearing-jupyter-notebook-cells","title":"\u2728 Auto-clearing Jupyter Notebook Cells","text":"<p>In Machine Learning projects, the output of text in Jupyter cells can be very large. This hook automatically clears all the cells in a notebook before allowing them to be committed to Git.</p> <pre><code>- repo: https://github.com/kynan/nbstripout\nrev: 0.6.1\nhooks:\n- id: nbstripout\n</code></pre>"},{"location":"python-machine-learning-template/pre-commit/#optional-pre-commit-hooks","title":"\ud83d\udd0c Optional Pre-commit Hooks","text":"<p>While the following hooks are not implemented by default, it is highly recommended as they can ensure your code conforms to PEP8 standards.</p>"},{"location":"python-machine-learning-template/pre-commit/#stop-direct-commits-to-the-main-branch","title":"\ud83d\udeab Stop Direct Commits to the Main Branch","text":"<p>In a project, the <code>main</code> branch is like the final copy of your code. It's important to keep this branch clean and error-free. So, instead of directly making changes to the <code>main</code> branch, we usually make changes in a different branch and then combine it with the <code>main</code> branch. This combining process is called a Pull Request (PR).</p> <p>But, what if someone accidentally makes a change directly in the <code>main</code> branch?</p> <p>Here's a pre-commit hook that stops us from committing changes directly to the <code>main</code> branch:</p> <pre><code>- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v3.4.0\nhooks:\n- id: no-commit-to-branch\nargs: ['--branch', 'main']\n</code></pre> <p>By using this, we make sure that the main branch is safe from direct changes. This way, we can keep our main branch clean and our code error-free.</p>"},{"location":"python-machine-learning-template/pre-commit/#auto-formatting-python-code","title":"\ud83d\udd25 Auto-formatting Python Code","text":"<p>This hook automatically formats your Python code to adhere to PEP8 standards.</p> <pre><code>- repo: https://github.com/psf/black\nrev: 22.6.0\nhooks:\n- id: black\n- id: black-jupyter\nlanguage_version: python3\n</code></pre>"},{"location":"python-machine-learning-template/pre-commit/#sort-all-your-python-imports","title":"\ud83c\udf08 Sort all your Python imports","text":"<pre><code>- repo: https://github.com/pycqa/isort\nrev: 5.10.1\nhooks:\n- id: isort\nname: isort (python)\n</code></pre>"},{"location":"python-machine-learning-template/pre-commit/#detecting-secrets-in-code-with-pre-commit-hook","title":"\ud83e\udded Detecting Secrets in Code with Pre-commit Hook","text":"<p>This pre-commit hook uses the Detect Secrets tool to prevent committing any kind of sensitive information unintentionally. It scans all files before each commit and compares them with a baseline to ensure no secrets are being committed.</p> <pre><code>- repo: https://github.com/Yelp/detect-secrets\nrev: v1.3.0\nhooks:\n- id: detect-secrets\nname: Detect Secrets\nlanguage: python\nargs: ['--baseline', '.secrets.baseline']\n</code></pre>"},{"location":"python-machine-learning-template/pre-commit/#code-formatting-and-upgrade-for-jupyter-notebooks","title":"\u2702\ufe0f Code Formatting and Upgrade for Jupyter Notebooks","text":"<p>This pre-commit hook uses the <code>nbQA</code> tool to run Python tools on Jupyter Notebooks. It includes hooks for Black (for code formatting), pyupgrade (for upgrading code to use the latest Python features), and isort (for sorting imports).</p> <p>This is directly taken from offical nbQA documentation</p> <pre><code>- repo: https://github.com/nbQA-dev/nbQA\nrev: 1.7.0\nhooks:\n- id: nbqa-black\nadditional_dependencies: [black==20.8b1]\n- id: nbqa-pyupgrade\nadditional_dependencies: [pyupgrade==2.7.3]\n- id: nbqa-isort\nadditional_dependencies: [isort==5.6.4]\n</code></pre> <p>These pre-commit hooks help to maintain the quality of your code and notebooks, ensuring they are clean, readable, and free from sensitive information.</p> <p>In order to install additional hooks like the few stated above, please follow the above steps</p>"},{"location":"python-machine-learning-template/pre-commit/#bypassing-pre-commit-checks","title":"\ud83d\udea7 Bypassing Pre-Commit Checks","text":"<p>Pre-commit hooks are installed to enforce certain rules and maintain code quality. However, in rare cases, you might find yourself needing to bypass these checks. While it's generally not recommended to do this, it's important to know how it can be done if the situation calls for it.</p> <p>Here's how you can bypass pre-commit checks:</p> <pre><code>git commit --no-verify -m \"Your commit message\"\n</code></pre> <p>This command will allow you to commit your changes without running the pre-commit checks. Remember, this should only be used in exceptional circumstances and not as a regular practice.</p>"},{"location":"python-machine-learning-template/prerequisites/","title":"\ud83d\udd11 Prerequisites for Project Setup","text":"<p>Before you begin setting up this project, ensure you have the following requirements in place:</p> <ol> <li> <p>Python: It's essential to have Python installed on your system. We highly recommend using the official CPython distribution, which can be obtained from python.org.</p> </li> <li> <p>Virtual Environment: A virtual environment is required to manage the project's dependencies separately from your global Python environment. </p> <p>Note</p> <p>If you're using Python 3.3 or a newer version, we strongly advise utilizing the <code>venv</code> module. This module is included in the Python standard library and doesn't require any additional installation.</p> </li> <li> <p>VS Code (Optional): While not mandatory, we highly recommend using Visual Studio Code (VS Code) as your code editor for all your projects.</p> </li> </ol> <p>These prerequisites are minimal and straightforward to fulfill, ensuring that the project setup process is hassle-free.</p>"},{"location":"python-machine-learning-template/prerequisites/#prerequisite-installation-instructions","title":"Prerequisite installation instructions","text":"\ud83d\udc27Linux\ud83c\udf4e MacOS\ud83e\ude9f Windows"},{"location":"python-machine-learning-template/prerequisites/#installing-python3-on-linux","title":"\ud83d\ude80 Installing Python3 on Linux","text":"<ol> <li> <p>Open the Terminal.</p> </li> <li> <p>Update your local package index and upgrade all your installed packages to their latest versions by running the following command:</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n</code></pre> </li> <li> <p>Install the necessary dependencies for Python3 by running the following command:</p> <pre><code>sudo apt install software-properties-common build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev\n</code></pre> </li> <li> <p>Add the deadsnakes PPA to your sources. This repository contains the latest versions of Python. Run the following command to add it:</p> <pre><code>sudo add-apt-repository ppa:deadsnakes/ppa\n</code></pre> </li> <li> <p>Update your local package index again to include the packages from the newly added repository by running the following command:</p> <pre><code>sudo apt update\n</code></pre> </li> <li> <p>Install Python3, pip (Python's package manager), and the virtual environment package by running the following command:</p> <pre><code>sudo apt install python3 python3-pip python3-venv\n</code></pre> </li> <li> <p>Check the installed version of Python3 by running the following command:</p> <pre><code>python3 --version\n</code></pre> </li> </ol> <p>This should display the version of Python3 that you just installed.</p>"},{"location":"python-machine-learning-template/prerequisites/#install-vs-code-on-linux","title":"\ud83c\udfa8 Install VS Code on Linux","text":"<ol> <li> <p>Install Visual Studio Code via Snap. </p> <p>Snap is a software deployment and package management system developed by Canonical (the company behind Ubuntu). It allows you to install software and all its dependencies via a single command. Run the following command to install Visual Studio Code:</p> <pre><code>sudo snap install --classic code\n</code></pre> </li> <li> <p>Check that Visual Studio Code has been installed correctly by running the following command:</p> <pre><code>code --version\n</code></pre> </li> </ol> <p>This should display the version of Visual Studio Code that you just installed.</p>"},{"location":"python-machine-learning-template/prerequisites/#references","title":"References:","text":"<ol> <li>Getting Started with Python in VS Code </li> <li>How to Install Python in Ubuntu</li> </ol>"},{"location":"python-machine-learning-template/prerequisites/#installing-python3-on-macos","title":"\ud83d\udef0\ufe0f Installing Python3 on MacOS","text":"<ol> <li> <p>Open the Terminal application by pressing command + space, typing terminal, and hitting return.</p> </li> <li> <p>Check if Python 3 is installed on your Mac by typing the following command in the Terminal:</p> <pre><code>python3 --version\n</code></pre> <p>If Python 3 is not installed, a message will appear in the Terminal, and a dialog box will pop up saying this command requires the command line developer tools. Click on the Install button and follow the steps to complete the installation process.</p> </li> <li> <p>Once the installation process is complete, rerun the previous command. Python 3.x should now be installed on your Mac.</p> </li> </ol> <p>Alternatively, you can install Python 3 using the Official Installer:</p> <ol> <li> <p>Visit the Python official website on your Mac. The website should automatically detect your operating system and show a big button for downloading the latest Python installer for your Mac. If it doesn't, click the macOS link and choose the latest Python release.</p> </li> <li> <p>Once the download is complete, double-click the package to start installing Python. The installer will guide you through the installation process. In most cases, the default settings work well. You may also need to enter your Mac password to authorize the installation.</p> </li> <li> <p>When the installation completes, it will open up the Python folder.</p> </li> <li> <p>Verify that the latest version of Python and IDLE installed correctly. To do this, double-click IDLE, which is the integrated development environment that comes with Python. If everything works correctly, IDLE will display the Python shell.</p> </li> </ol>"},{"location":"python-machine-learning-template/prerequisites/#install-vs-code-on-macos","title":"\ud83c\udfa8 Install VS Code on MacOS","text":"<ol> <li> <p>Download Visual Studio Code for MacOS from VS Code official website.</p> </li> <li> <p>Double-click the downloaded file to extract the archived contents.</p> </li> <li> <p>Move the Visual Studio Code application to the Applications folder to make it available in the MacOS Launchpad.</p> </li> <li> <p>Launch Visual Studio Code, then open a folder where your Python scripts are located (or create a new one). For example, create a new folder on your Desktop named \"py_scripts\", then try to open the folder in VS Code. VS Code may need your permission to access files in your Desktop folder; click OK if prompted.</p> </li> <li> <p>Create a new file with a .py extension. For example, create a new file named <code>prog_01.py</code>. VS Code will detect the <code>.py</code> extension and suggest installing a Python extension. Install it by clicking on the Install button.</p> </li> <li> <p>Once the extension is installed, you need to select a Python interpreter. Click on the \"Select Python Interpreter\" button and then select the recommended Python interpreter from the list. If you have multiple versions of Python installed on your Mac, it's best to choose the latest version.</p> </li> </ol> <p>You can now write and run Python code inside VS Code.</p>"},{"location":"python-machine-learning-template/prerequisites/#references_1","title":"References:","text":"<ol> <li>Getting Started with Python in VS Code</li> <li>Tutorial: Installing Python on Mac</li> </ol>"},{"location":"python-machine-learning-template/prerequisites/#installing-python3-on-windows","title":"\ud83d\udef8 Installing Python3 on Windows","text":"<ol> <li> <p>Download the latest Python distribution from the Official Python website. </p> </li> <li> <p>Double-click on the file to run the installer.</p> </li> <li> <p>In the installer, make sure you check the box that says \"Add Python 3.7 to PATH\" and then click on \"Install Now\". This will start the installation process.</p> </li> <li> <p>Once the installation is complete, you can verify the installation. To do this, open a new command prompt window. You can do this by pressing the Windows key, typing \"cmd\", and hitting Enter.</p> </li> <li> <p>In the command prompt window, type the following command:</p> <pre><code>python --version\n</code></pre> </li> </ol>"},{"location":"python-machine-learning-template/prerequisites/#install-vs-code-on-windows","title":"\ud83c\udfa8 Install VS Code on Windows","text":"<ol> <li>Download the Visual Studio Code installer for Windows.</li> <li>Once it is downloaded, run the installer (VSCodeUserSetup-{version}.exe). This will only take a minute.</li> <li>By default, VS Code is installed under <code>C:\\Users\\{Username}\\AppData\\Local\\Programs\\Microsoft VS Code</code>.</li> </ol> <p>Alternatively, you can also download a Zip archive, extract it and run Code from there.</p>"},{"location":"python-machine-learning-template/process-flow/","title":"\ud83c\udfae How to start using this template?","text":"<p>The Python Machine Learning Template is designed to be user-friendly and easy to start with. </p> <p>Here is a simple process flow to get you started:</p> <pre><code>\ngraph TB\n  A[\"Go to Python Machine Learning Template on Github\"] -- \"Click on Use this template button\" --&gt; B[\"Create your repository using this template\"]\n  B -- \"Wait for 1 minute\" --&gt; C[\"Github actions bot cleans and prepares your project\"]\n  C -- \"Copy project clone URL\" --&gt; D[\"Clone your project on your machine\"]\n  D -- \"Setup your project\" --&gt; E[\"Use the setup instructions provided in this guide\"]\n</code></pre> Process Flow"},{"location":"python-machine-learning-template/process-flow/#step-by-step-instructions","title":"\ud83e\ude9c Step-by-step instructions","text":"<ol> <li> <p>Go to Python Machine Learning Template on Github.</p> </li> <li> <p>Click on \"Use this template\" button to create your project. Github provides this feature which allows you to create a new repository using the template.</p> <p>Option 1</p> <p> Option 1:  You can select the highlighed button or link </p> <p>The Readme also contains a button which has the same functionality, it directs you to project creation page.</p> <p>Option 2</p> <p> Option 2:  You can select the highlighed button here as well </p> </li> <li> <p>Wait for 1 minute after creating your repository. During this time, the Github actions bot cleans and prepares your project.</p> </li> <li> <p>Once the Github actions bot has prepared your project, you can clone it onto your machine.</p> </li> <li> <p>After cloning the project, you can set it up using the setup instructions provided in this section.</p> </li> </ol>"},{"location":"python-machine-learning-template/project-setup/","title":"\ud83d\ude80 Platform-Specific Setup Scripts","text":"<ul> <li> <p>\ud83d\udea6 Ready-to-Use Scripts for All Platforms: We have prepared setup scripts for Linux, MacOS, and Windows platforms to ensure that the virtual environment is set up consistently across all platforms. These scripts will save you time and effort in setting up your project.</p> </li> <li> <p>\ud83d\udce6 Package Installation: To simplify package installation and maintainence, we use pipenv instead of pip. For more details, please refer to the Pipenv documentation.</p> </li> <li> <p>\ud83c\udf10 Proxy Support: If you work behind a proxy, you may need to configure your proxy url in the <code>.env</code> file that gets generated once you run the setup scripts and pass the relevant argument to the setup script to enable pacakge installation. For more details, check out our documentation on working with .env</p> </li> <li> <p>\ud83d\uddd1\ufe0f Readme Cleanup: Utilize relevant argument in the setup script to automatically clear the content of template Readme.MD file. More detailed instructions on usage below.</p> </li> <li> <p>\ud83d\udca1 Virtual Environment: Upon successful execution of the setup script, your terminal will automatically activate a virtual environment named <code>.venv</code>.</p> </li> </ul>"},{"location":"python-machine-learning-template/project-setup/#setup-script-usage","title":"Setup script usage","text":""},{"location":"python-machine-learning-template/project-setup/#for-linuxmacos","title":"For Linux/MacOS","text":"<pre><code>source project_setup.sh [OPTIONS] </code></pre>"},{"location":"python-machine-learning-template/project-setup/#for-windows-os","title":"For Windows OS","text":"<pre><code>project_setup.bat [OPTIONS]\n</code></pre> <p>Replace [OPTIONS] with any combination of the following supported arguments:</p> <ul> <li> <p><code>--install</code>: Required argument. If nothing is passed, a help message is displayed by default.</p> </li> <li> <p><code>--install-dev</code>: Use this flag along with <code>--install</code> flag to install development packages.</p> </li> <li> <p><code>--use-proxy</code>: Use this flag to enable installation of python packages behind proxy.</p> </li> <li> <p><code>--unset-proxy</code>: Use this flag to disable proxy.</p> </li> <li> <p><code>--clear-readme</code>: Use this flag to clear the contents of <code>README.md</code> file after setting up the project.</p> <ul> <li>\ud83d\udce3 Caution: This should be used only once when you are setting up the project for the first time.</li> </ul> </li> <li> <p><code>--remove-cache</code>: Use this flag to remove <code>pip</code> and <code>pipenv</code> cache files.</p> <ul> <li>\ud83d\udca1 Use this to clear cache files generated during package installation</li> </ul> </li> <li> <p><code>--help</code>: Use this flag to display the help message.</p> </li> </ul>"},{"location":"python-machine-learning-template/project-setup/#detailed-steps","title":"Detailed steps","text":"\ud83d\udc27  Linux / \ud83c\udf4e MacOS\ud83e\ude9f Windows <p>For setting up the project on these platforms, <code>project_setup.sh</code> script has been provided along with some options. Check Setup script usage section for details.</p> <p>For setting up the project on Windows, <code>project_setup.bat</code> script has been provided along with some options.</p>"},{"location":"python-machine-learning-template/project-setup/#steps-for-linuxmacos","title":"\ud83e\uddd1\u200d\ud83d\udcbb Steps for Linux/MacOS:","text":"<ol> <li> <p>Open terminal and navigate to your project directory.</p> Case (a): \ud83d\udd30 Setting up in Development environmentCase (b): \ud83c\udfc1 Setting up in Production environment <ul> <li> <p>If you are setting up the project inside development environment, use:</p> <pre><code>source project_setup.sh --install --install-dev\n</code></pre> <ul> <li> <p>Incase you are working behind a proxy, use the following command instead:</p> <pre><code>source project_setup.sh --install --install-dev --use-proxy\n</code></pre> </li> </ul> </li> <li> <p>If you are setting up the project first time using this template, then you should replace contents of the README.md with the name of your project:</p> <pre><code>source project_setup.sh --clear-readme\n</code></pre> <p>\u26a0\ufe0f  *** Use this command only once in the development environment. DO NOT run this once you write your own readme. ***</p> </li> </ul> <ul> <li> <p>If you are setting up the project inside production environment, you may only require base packages, use:</p> <pre><code>source project_setup.sh --install\n</code></pre> <ul> <li> <p>Incase you are working behind a proxy, use the following command instead:</p> <pre><code>source project_setup.sh --install --use-proxy\n</code></pre> </li> </ul> </li> </ul> <p>Important Note</p> <ul> <li> <p>\u26fd If want to install any other package inside this newly created virtual environment, please use the following command:</p> <pre><code>pipenv install package_name\n</code></pre> </li> <li> <p>\u274e If you have configured proxy details in the <code>.env</code> file but later on you are not working behind proxy, you'd get package installation error as by default, <code>pipenv</code> loads all the <code>.env</code> variables, therefore you need to unset the proxy first.</p> <p>Use the following command:</p> <pre><code>source project_setup.sh --unset-proxy\n</code></pre> <p>You should then be able to install packages using pipenv as stated above.</p> </li> <li> <p>\u267b\ufe0f During package installation, the packages are downloaded and cached. This consumes a lot of disk, hence you should clear pip and pipenv cache from time to time. </p> <p>Use the following command:</p> <p><pre><code>source project_setup.sh --remove-cache\n</code></pre> This would remove all the cached files during package installation.</p> </li> <li> <p>\u2705 To ensure a conflict-free environment setup, it is strongly recommended to always run the <code>project_setup.sh</code> script to create a virtual environment for your project.</p> </li> <li> <p>\u2757You should run the script ONLY using the <code>source</code> command to ensure that the virtual environment <code>.venv</code> is automatically activated at the end of setup in the current shell session.</p> </li> <li> <p>\u26d4 Ideally, you should see a <code>.venv</code> virtual environment already activated in the terminal. However, if it's not activated, please follow these steps to activate it before installing any package using pipenv:</p> <ol> <li> <p>Open terminal.</p> </li> <li> <p>Navigate to the project directory.</p> </li> <li> <p>Activate the virtual environment by running the following command: <code>source .venv/bin/activate</code>. This command will activate the virtual environment and change your prompt to indicate that you're now working within it.</p> </li> <li> <p>You can now proceed with installing packages using <code>pipenv</code></p> </li> </ol> </li> </ul> </li> </ol>"},{"location":"python-machine-learning-template/project-setup/#steps-for-windows","title":"\ud83e\uddd1\u200d\ud83d\udcbb Steps for Windows:","text":"<ol> <li> <p>Open Command Prompt (CMD) and navigate to your project directory.</p> Case (a): \ud83d\udd30 Setting up in Development environment Case (b): \ud83c\udfc1 Setting up in Production environment,  <ul> <li> <p>If you are setting up the project inside development environment, use:</p> <pre><code>project_setup.bat --install --install-dev\n</code></pre> <ul> <li> <p>Incase you are working behind a proxy, use the following command instead:</p> <pre><code>project_setup.bat --install --install-dev --use-proxy\n</code></pre> </li> </ul> </li> <li> <p>If you are setting up the project first time using this template, then you should replace contents of the README.md with the name of your project:</p> <pre><code>project_setup.bat --clear-readme\n</code></pre> <p>\u26a0\ufe0f Use this command only once in the development environment. DO NOT run this once you write your own readme.</p> </li> </ul> <ul> <li> <p>If you are setting up the project inside production environment, you may only require base packages to be installaed, use:</p> <pre><code>project_setup.bat --install\n</code></pre> <ul> <li> <p>Incase you are working behind a proxy, use the following command instead:</p> <pre><code>project_setup.bat --install --use-proxy\n</code></pre> </li> </ul> </li> </ul> <p>Important Note</p> <ul> <li> <p>\u26fd If want to install any other package inside this newly created virtual environment, please use the following command:</p> <pre><code>pipenv install package_name\n</code></pre> </li> <li> <p>\u274e If you have configured proxy details in the <code>.env</code> file but later on you are not working behind proxy, you'd get package installation error as by default, <code>pipenv</code> loads all the <code>.env</code> variables, therefore you need to unset the proxy first.</p> <p>Use the following command:</p> <pre><code>project_setup.bat --unset-proxy\n</code></pre> <p>You should then be able to install packages using pipenv as stated above.</p> </li> <li> <p>\u267b\ufe0f During package installation, the packages are downloaded and cached. This consumes a lot of disk, hence you should clear pip and pipenv cache from time to time. </p> <p>Use the following command:</p> <p><pre><code>project_setup.bat --remove-cache\n</code></pre> This would remove all the cached files during package installation.</p> </li> <li> <p>\u2705 To ensure a conflict-free environment setup, it is strongly recommended to always run the <code>project_setup.bat</code> script to create a virtual environment for your project.</p> </li> <li> <p>\u2757For security reasons, organizations may prevent running .bat scripts on PowerShell. You should run the script ONLY on Command Prompt (CMD) to ensure that everything runs without any errors.</p> </li> <li> <p>\u26d4 Ideally, you should see a <code>.venv</code> virtual environment already activated in the Command Prompt (CMD). However, if it's not activated, please follow these steps to activate it before installing any package using <code>pipenv</code>:</p> <ol> <li>Open the Command Prompt (CMD).</li> <li>Navigate to the project directory.</li> <li> <p>Activate the virtual environment by running the following command: <code>.venv\\Scripts\\Activate</code>. This command will activate the virtual environment and change your prompt to indicate that you're now working within it.</p> </li> <li> <p>You can now proceed with installing packages using <code>pipenv</code></p> </li> </ol> </li> </ul> </li> </ol>"},{"location":"python-machine-learning-template/project-setup/#demo","title":"\ud83c\udfa5 Demo","text":"<ul> <li> <p>\ud83c\udf04 This demo assumes that you've cloned the project which you created using the Python Machine Learning Template on your machine. For the purposes of this demonstration, we'll refer to this project as <code>Demo Project</code>.</p> </li> <li> <p>\ud83c\udfc3 The video tutorial will guide you through the necessary steps for setting up your project. </p> <p></p> </li> </ul>"},{"location":"python-machine-learning-template/setup.py/","title":"\ud83d\udce6 Packaging your Project with setup.py","text":"<p>When working with a project structure like this where supporting code resides in folders at the same level as the <code>src</code> or <code>notebooks</code> folder, you will not be able to import sub-modules from the <code>helpers</code> folder into the main/entrypoint code in the <code>src</code> folder even though it contains <code>__init__.py</code> file indicating that it can be used as a module.</p> <p>For example, let us say you have a file named <code>helper.py</code> under <code>helpers</code> folder</p> helper.py<pre><code>import numpy as np\n\ndef test_numpy():\n    print(\"Using Numpy\")\n    a = np.array([10, 20])\n    print(\"Array: \", a)\n</code></pre> <p>and you are trying to use this <code>helper.py</code> in your code under the <code>src</code> folder</p> test_code.py<pre><code>from helpers import helper\n\nhelper.test_numpy()\n</code></pre> <p>When you run the code from the project root <code>python src/test_code.py</code>, you will be greeted with the following error:</p> <pre><code>Traceback (most recent call last):\n  File \"src/test_code.py\", line 1, in &lt;module&gt;\n    from helpers import helper\nModuleNotFoundError: No module named 'helpers'\n</code></pre> <p>This can be resolved by utilizing <code>setup.py</code> in your project.</p> <p>Here's a step-by-step guide to achieving this:</p> <ol> <li> <p>\ud83d\udcc2 Open the <code>setup.py</code> file provided in the template. At very basic level, it looks like this:</p> setup.py<pre><code>from setuptools import find_packages, setup\n\nsetup(\n    name=\"YOUR-PROJECT-NAME\",\n    version=\"1.0\",\n    packages=find_packages(),\n)\n</code></pre> </li> <li> <p>\u270f\ufe0f Update the <code>name</code> variable in <code>setup.py</code> to match the root folder name of your project. This step ensures your project is properly identified.</p> </li> <li> <p>\ud83d\udda5\ufe0f Open the terminal or Command Prompt (CMD) and navigate to the project directory. Ensure you are in the root folder of your project and your project's virtual environment is active.</p> Note <ul> <li> <p>\ud83e\udd14 If you have doubts regarding virtual environment activation, refer to the project setup section for detailed instructions tailored to your specific operating system.</p> </li> <li> <p>\ud83d\ude0e An <code>__init__.py</code> file is already present in the helpers folder. The presence of this file allows the helpers folder to function as a module that can be accessed from anywhere within the package.</p> </li> </ul> </li> <li> <p>\u25b6\ufe0f Run the following command in your terminal or CMD: </p> <pre><code>    pipenv install -e .\n</code></pre> Note <ul> <li> <p>\u2705 Ensure you include the <code>.</code> at the end of the command. This command installs your project as a package, granting it importability and enabling you to organize your code in a modular and convenient manner.</p> </li> <li> <p>\ud83c\udd97 This should automatically add your project as a package to your current virtual environment. You can verify the same in your <code>Pipfile</code>. You should see the following line:</p> <p><code>your-project-name = {editable = true, path = \".\"}</code></p> </li> </ul> </li> </ol> <p>Once the opertion is complete, now when you try to run the code from the project root <code>python src/test_code.py</code>, it now will run successfully. </p> <p>For the above example, it will show you the following output:</p> <pre><code>Using Numpy\nArray:  [10 20]\n</code></pre> About setup.py <p>\ud83d\udca1 The <code>setup.py</code> file is not limited to this, it is a much more powerful tool that can be leveraged for various other tasks which is a bit out of scope to explain it here.</p>"},{"location":"python-machine-learning-template/tox/","title":"\ud83e\uddea ** Leveraging <code>tox.ini</code>for Configuration Management**","text":"<p>In a Python project, maintaining consistent code quality and adhering to specific coding standards is crucial. Tools like <code>Flake8</code>, <code>Black</code>, <code>isort</code>, <code>mypy</code>, and others can assist with this. However, each of these tools may require a separate configuration file to read their settings and apply them to your code. If you're using multiple such tools, managing individual configuration files can become cumbersome.</p> <p>Enter tox! With tox, you can consolidate the settings for all these tools into a single <code>tox.ini</code> file, eliminating the need for multiple separate files. This makes your configuration management more streamlined and efficient.</p> <p>Here's an example of how you can define settings for <code>flake8</code> and <code>isort</code> in the <code>tox.ini</code> file:</p> <pre><code>[flake8]\nmax-line-length = 88\nextend-ignore = E203\nexclude = .git, __pycache__, .venv\nmax-line-length = 88\nuse-flake8-tabs = true\n\n[isort]\nprofile = black\nmulti_line_output = 3\n</code></pre> <p>Note</p> <p>It's important to note that tox is more than just a configuration file manager. The tox project is a powerful tool with a host of advanced features that you can explore for more complex use cases. In this template, we've primarily used <code>tox.ini</code> as a single source configuration file, but tox offers much more!</p>"},{"location":"python-machine-learning-template/workspaces/","title":"\ud83d\udc65 Multi-user Workspace for Collaborative Projects","text":"<p>The <code>workspaces</code> folder is intended for scenarios where multiple people are working on the same project on the same machine.</p> <p>Inside the <code>workspaces</code> folder, you can create subfolders named after each developer, allowing them to clone the project and work on different branches. </p> <p>The template has been cleverly configured in a way that git will not track these subdirectories from the root of the project but inside each of the cloned project, git will work normally. This enables multiple people to collaborate on the same project without conflicts. </p> <p>To incorporate their individual changes, developers can merge their branches respective branch with a common branch located at the root level.</p> <pre><code>graph TB\n    A[Project Root] --&gt; B[Workspaces Folder]\n    B --&gt; C[Developer 1 Folder]\n    B --&gt; D[Developer 2 Folder]\n    B --&gt; E[Developer 3 Folder]\n    C --&gt; F[Developer 1 Branch]\n    D --&gt; G[Developer 2 Branch]\n    E --&gt; H[Developer 3 Branch]\n    F --&gt; I[Merge with Common Branch]\n    G --&gt; I\n    H --&gt; I\n    I --&gt; A\n</code></pre> Using workspaces directory <p>In this structure, the project root leads to a workspaces folder. This folder contains individual folders for each developer (Developer 1, Developer 2, Developer 3, etc.). Each developer works on their own branch within their respective folder. When they're ready to incorporate their changes, they merge their branch with a common branch located at the root level.</p>"}]}